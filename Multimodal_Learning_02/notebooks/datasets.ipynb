{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7315,
     "status": "ok",
     "timestamp": 1764792270689,
     "user": {
      "displayName": "Michele Marschner",
      "userId": "00906875642059722595"
     },
     "user_tz": -60
    },
    "id": "1qADO5m4vG4c"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1764792326332,
     "user": {
      "displayName": "Michele Marschner",
      "userId": "00906875642059722595"
     },
     "user_tz": -60
    },
    "id": "71HvJx-p0dI6"
   },
   "outputs": [],
   "source": [
    "CLASSES = [\"cubes\", \"spheres\"]\n",
    "LABEL_MAP = {\"cubes\": 0, \"spheres\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28248,
     "status": "ok",
     "timestamp": 1764792355500,
     "user": {
      "displayName": "Michele Marschner",
      "userId": "00906875642059722595"
     },
     "user_tz": -60
    },
    "id": "XcbFggPyuTJr",
    "outputId": "0b4b8502-5af8-497f-cb58-6e55c38866bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "STORAGE_PATH = Path(\"/content/drive/MyDrive/Colab Notebooks/Applied Computer Vision/Applied-Computer-Vision-Projects/Multimodal_Learning_02/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2561,
     "status": "ok",
     "timestamp": 1764792358059,
     "user": {
      "displayName": "Michele Marschner",
      "userId": "00906875642059722595"
     },
     "user_tz": -60
    },
    "id": "_2rhZwvMvKIl",
    "outputId": "8e61288d-d551-44f2-8b0f-11ff0dcb4108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: /content/drive/MyDrive/Colab Notebooks/Applied Computer Vision/Applied-Computer-Vision-Projects/Multimodal_Learning_02/multimodal_training_workshop/data\n",
      "Data path exists: True\n"
     ]
    }
   ],
   "source": [
    "DATA_SRC_PATH = STORAGE_PATH / \"multimodal_training_workshop/data\"\n",
    "DATA_DEST_PATH = STORAGE_PATH / \"data\"\n",
    "print(f\"Data path: {DATA_SRC_PATH}\")\n",
    "print(f\"Data path exists: {DATA_SRC_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1764792358074,
     "user": {
      "displayName": "Michele Marschner",
      "userId": "00906875642059722595"
     },
     "user_tz": -60
    },
    "id": "X0tZHSolvVuU"
   },
   "outputs": [],
   "source": [
    "def get_torch_xyza(lidar_depth, azimuth, zenith):\n",
    "    x = lidar_depth * torch.sin(-azimuth[:, None]) * torch.cos(-zenith[None, :])\n",
    "    y = lidar_depth * torch.cos(-azimuth[:, None]) * torch.cos(-zenith[None, :])\n",
    "    z = lidar_depth * torch.sin(-zenith[None, :])\n",
    "    a = torch.where(lidar_depth < 50.0, torch.ones_like(lidar_depth), torch.zeros_like(lidar_depth))\n",
    "    xyza = torch.stack((x, y, z, a))\n",
    "    return xyza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1764792688613,
     "user": {
      "displayName": "Michele Marschner",
      "userId": "00906875642059722595"
     },
     "user_tz": -60
    },
    "id": "ywFymdb7vWM4"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def precompute_assessment_xyza(\n",
    "    src_root,\n",
    "    dst_root,\n",
    "    classes,\n",
    "    label_map,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert assessment depth LiDAR (H,W) to XYZA (4,H,W) and save to dst_root.\n",
    "    \"\"\"\n",
    "    src_root = Path(src_root)\n",
    "    dst_root = Path(dst_root)\n",
    "    dst_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_samples = []\n",
    "\n",
    "    for class_name in classes:\n",
    "        src_class_dir = src_root / class_name\n",
    "        rgb_dir   = src_class_dir / \"rgb\"\n",
    "        lidar_dir = src_class_dir / \"lidar\"\n",
    "\n",
    "        # azimuth / zenith per class\n",
    "        azimuth_path = src_class_dir / \"azimuth.npy\"\n",
    "        zenith_path  = src_class_dir / \"zenith.npy\"\n",
    "        if not azimuth_path.exists() or not zenith_path.exists():\n",
    "            raise FileNotFoundError(f\"Missing azimuth/zenith in {src_class_dir}\")\n",
    "\n",
    "        azimuth = torch.from_numpy(np.load(azimuth_path)).to(torch.float32)\n",
    "        zenith  = torch.from_numpy(np.load(zenith_path)).to(torch.float32)\n",
    "\n",
    "        # destination dirs\n",
    "        dst_class_dir = dst_root / class_name\n",
    "        dst_rgb_dir   = dst_class_dir / \"rgb\"\n",
    "        dst_lidar_dir = dst_class_dir / \"lidar_xyza\"\n",
    "\n",
    "        dst_rgb_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dst_lidar_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        rgb_files   = sorted(rgb_dir.glob(\"*.png\"))\n",
    "        lidar_files = sorted(lidar_dir.glob(\"*.npy\"))\n",
    "\n",
    "        rgb_stems   = {f.stem for f in rgb_files}\n",
    "        lidar_stems = {f.stem for f in lidar_files}\n",
    "        matching    = sorted(rgb_stems & lidar_stems)\n",
    "\n",
    "        print(f\"{class_name}: {len(matching)} paired samples\")\n",
    "\n",
    "        for stem in tqdm(matching, desc=f\"Converting {class_name}\"):\n",
    "            # --- RGB: copy to dst_root (or keep src, your choice) ---\n",
    "            rgb_src = rgb_dir / f\"{stem}.png\"\n",
    "            rgb_dst = dst_rgb_dir / f\"{stem}.png\"\n",
    "            if not rgb_dst.exists():\n",
    "                Image.open(rgb_src).save(rgb_dst)\n",
    "\n",
    "            # --- depth → XYZA ---\n",
    "            depth_src = lidar_dir / f\"{stem}.npy\"\n",
    "            depth_np  = np.load(depth_src)              # (H, W)\n",
    "            depth_t   = torch.from_numpy(depth_np).to(torch.float32)\n",
    "\n",
    "            xyza = get_torch_xyza(depth_t, azimuth, zenith)  # (4, H, W)\n",
    "\n",
    "            lidar_dst = dst_lidar_dir / f\"{stem}.npy\"\n",
    "            np.save(lidar_dst, xyza.numpy())\n",
    "\n",
    "            all_samples.append(\n",
    "                {\n",
    "                    \"class\": class_name,\n",
    "                    \"rgb\": rgb_dst,\n",
    "                    \"lidar_xyza\": lidar_dst,\n",
    "                    \"label\": label_map[class_name],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    print(f\"Total converted samples: {len(all_samples)}\")\n",
    "    return all_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6082509,
     "status": "ok",
     "timestamp": 1764798774011,
     "user": {
      "displayName": "Michele Marschner",
      "userId": "00906875642059722595"
     },
     "user_tz": -60
    },
    "id": "CZSz0viBv0JI",
    "outputId": "4d137733-3af0-44ab-da01-ac21cfd9475c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cubes: 2501 paired samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting cubes: 100%|██████████| 2501/2501 [20:09<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spheres: 9999 paired samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting spheres: 100%|██████████| 9999/9999 [1:18:52<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total converted samples: 12500\n"
     ]
    }
   ],
   "source": [
    "SRC = DATA_SRC_PATH / \"assessment\"\n",
    "DST = DATA_DEST_PATH\n",
    "\n",
    "all_samples_xyza = precompute_assessment_xyza(src_root=SRC,\n",
    "    dst_root=DST,\n",
    "    classes=CLASSES,\n",
    "    label_map=LABEL_MAP,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1AU5CD1y-iT"
   },
   "outputs": [],
   "source": [
    "print(len(all_samples_xyza))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPegMDOgJFz4vSVyknQy7dW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
