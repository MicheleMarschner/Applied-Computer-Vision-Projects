{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture\n",
        "\n",
        "```\n",
        "RGB ----> RGB Encoder ----\\\n",
        "                            ----> Fusion ---> Classifier ---> cube/sphere\n",
        "LiDAR -> LiDAR Encoder ----/\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "oWxsDGcq0xVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Architecture Flow:**\n",
        "\n",
        "```\n",
        "RGB Input (4ch)       LiDAR Input (4ch)\n",
        "      │                     │\n",
        "[RGB Encoder]         [XYZ Encoder]    <-- Learn specific features independently\n",
        "      │                     │\n",
        "  RGB Features          XYZ Features   <-- (e.g. 128 channels each)\n",
        "      └──────────┬──────────┘\n",
        "                 │\n",
        "           Concatenation               <-- Fuse at the \"Feature Level\"\n",
        "                 │\n",
        "         [Regression Head]             <-- Learn relationships between features\n",
        "                 │\n",
        "           Output (x,y,z)\n",
        "```"
      ],
      "metadata": {
        "id": "8cFYDTuJt5AF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multimodal fusion refers to how we combine information from different modalities (e.g., RGB and LiDAR).\n",
        "There are three canonical levels of fusion:\n",
        "\n",
        "Early fusion – combine raw or early-level features\n",
        "\n",
        "Intermediate fusion – combine learned feature representations\n",
        "\n",
        "Late fusion – combine decisions or latent vectors at the end of the pipeline;  it's almost like we're creating an ensemble model, where each model has a weighted vote in the final result.\n",
        "\n",
        "Each level has different strengths + limitations."
      ],
      "metadata": {
        "id": "tVHp70DLYlaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "w79TQtD755-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations & Imports"
      ],
      "metadata": {
        "id": "GObSvKFDxblW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install wandb weave"
      ],
      "metadata": {
        "id": "dodCKTTU7C_t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install fiftyone==1.10.0 sympy==1.12 torch==2.9.0 torchvision==0.20.0 numpy open-clip-torch"
      ],
      "metadata": {
        "id": "KtirMD1x7EU8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ukkECgFX5HQT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.v2 as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "import pandas as pd\n",
        "\n",
        "import wandb\n",
        "import cv2\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Storage"
      ],
      "metadata": {
        "id": "A6GLz8wSxY2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## stays - ggf. wo gebraucht\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "STORAGE_PATH = Path(\"/content/drive/MyDrive/Colab Notebooks/Applied Computer Vision/Applied-Computer-Vision-Projects/Multimodal_Learning_02/\")\n",
        "\n",
        "DATA_PATH = STORAGE_PATH / \"multimodal_training_workshop/data\"\n",
        "print(f\"Data path: {DATA_PATH}\")\n",
        "print(f\"Data path exists: {DATA_PATH.exists()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5rX_aoY7M_g",
        "outputId": "2e5797d8-1150-428b-f117-055ee45863e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data path: /content/drive/MyDrive/Colab Notebooks/Applied Computer Vision/Applied-Computer-Vision-Projects/Multimodal_Learning_02/multimodal_training_workshop/data\n",
            "Data path exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rsync -ah --progress \"/content/drive/MyDrive/Colab Notebooks/Applied Computer Vision/Applied-Computer-Vision-Projects/Multimodal_Learning_02/data\" \"/content/data/\"\n"
      ],
      "metadata": {
        "id": "0qQeea1oLVvJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## stays\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "9bGm3AQAGbBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc274f1-5a85-48cd-d95f-cb990a543172"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "8gr2RzKsxfDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## stays\n",
        "\n",
        "SEED = 51\n",
        "NUM_WORKERS = os.cpu_count()  # Number of CPU cores\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 64\n",
        "\n",
        "CLASSES = [\"cubes\", \"spheres\"]\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "LABEL_MAP = {\"cubes\": 0, \"spheres\": 1}\n",
        "\n",
        "VALID_BATCHES = 10\n",
        "N = 12500\n",
        "EPOCHS = 15\n",
        "LR = 0.0001"
      ],
      "metadata": {
        "id": "PTMc18ZD5_lr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration of Wandb"
      ],
      "metadata": {
        "id": "oq3nlu7A7Qr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## stays\n",
        "\n",
        "# Load W&B API key from Colab Secrets and make it available as env variable\n",
        "wandb_key = userdata.get('WANDB_API_KEY')\n",
        "os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "LQPywS8q7UrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d10857-33d1-4289-98b0-1b8760243366"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## move: training.py\n",
        "\n",
        "def init_wandb(model, fusion_name, num_params, opt_name, batch_size=BATCH_SIZE, epochs=15):\n",
        "  \"\"\"\n",
        "  Initialize a Weights & Biases run for a given fusion model.\n",
        "\n",
        "  Args:\n",
        "      model (nn.Module): The PyTorch model to track.\n",
        "      fusion_name (str): Short name of the fusion strategy (e.g. \"early_fusion\").\n",
        "      num_params (int): Total number of trainable parameters of the model.\n",
        "      opt_name (str): Name of the optimizer (e.g. \"Adam\").\n",
        "      batch_size (int, optional): Batch size used during training.\n",
        "      epochs (int, optional): Number of training epochs.\n",
        "\n",
        "  Returns:\n",
        "      wandb.sdk.wandb_run.Run: The initialized W&B run object.\n",
        "  \"\"\"\n",
        "\n",
        "  config = {\n",
        "    # \"embedding_size\": embedding_size,      ## TODO: ändert die sich? hab ich die bei fusion?\n",
        "    \"optimizer_type\": opt_name,\n",
        "    \"fusion_strategy\": fusion_name,\n",
        "    \"model_architecture\": model.__class__.__name__,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"num_epochs\": epochs,\n",
        "    \"num_parameters\": num_params\n",
        "  }\n",
        "\n",
        "  run = wandb.init(\n",
        "    project=\"cilp-extended-assessment\",\n",
        "    name=f\"{fusion_name}_run\",\n",
        "    config=config,\n",
        "    reinit='finish_previous',                           # allows starting a new run inside one script\n",
        "  )\n",
        "\n",
        "  return run"
      ],
      "metadata": {
        "id": "61o0qKeGiDGo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions\n",
        "\n",
        "alle in utility.py reinschieben\n",
        "\n"
      ],
      "metadata": {
        "id": "ayZXNwxXGqUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=SEED):\n",
        "    \"\"\"\n",
        "    Set seeds for complete reproducibility across all libraries and operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int): Random seed value\n",
        "    \"\"\"\n",
        "    # Set environment variables before other imports\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "    # Python random module\n",
        "    random.seed(seed)\n",
        "\n",
        "    # NumPy\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # PyTorch CPU\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # PyTorch GPU (all devices)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
        "\n",
        "        # CUDA deterministic operations\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # OpenCV\n",
        "    cv2.setRNGSeed(seed)\n",
        "\n",
        "    # Albumentations (for data augmentation)\n",
        "    try:\n",
        "        A.seed_everything(seed)\n",
        "    except AttributeError:\n",
        "        # Older versions of albumentations\n",
        "        pass\n",
        "\n",
        "    # PyTorch deterministic algorithms (may impact performance)\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except RuntimeError:\n",
        "        # Some operations don't have deterministic implementations\n",
        "        print(\"Warning: Some operations may not be deterministic\")\n",
        "\n",
        "    print(f\"All random seeds set to {seed} for reproducibility\")\n",
        "\n",
        "\n",
        "\n",
        "# Usage: Call this function at the beginning and before each training phase\n",
        "set_seeds(SEED)\n",
        "\n",
        "# Additional reproducibility considerations:\n",
        "\n",
        "def create_deterministic_training_dataloader(dataset, batch_size, shuffle=True, **kwargs):\n",
        "    \"\"\"\n",
        "    Create a DataLoader with deterministic shuffling behaviour.\n",
        "\n",
        "    Args:\n",
        "        dataset (Dataset): PyTorch Dataset instance.\n",
        "        batch_size (int): Batch size.\n",
        "        shuffle (bool): Whether to shuffle data.\n",
        "        **kwargs: Additional DataLoader keyword arguments.\n",
        "\n",
        "    Returns:\n",
        "        DataLoader: Training DataLoader with reproducible sampling.\n",
        "    \"\"\"\n",
        "    # Use a generator with fixed seed for reproducible shuffling\n",
        "    generator = torch.Generator()\n",
        "    generator.manual_seed(SEED)\n",
        "\n",
        "    return torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        generator=generator if shuffle else None,\n",
        "        **kwargs\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lccenR_P0TMW",
        "outputId": "06d3311a-e890-4764-9271-0503d18c0abb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random seeds set to 51 for reproducibility\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(seconds):\n",
        "    \"\"\"\n",
        "    Convert a duration in seconds to a human-readable 'MMm SSs' string.\n",
        "\n",
        "    Args:\n",
        "        seconds (float): Duration in seconds.\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted duration, e.g. \"02m 15s\".\n",
        "    \"\"\"\n",
        "    m = int(seconds // 60)\n",
        "    s = int(seconds % 60)\n",
        "    return f\"{m:02d}m {s:02d}s\""
      ],
      "metadata": {
        "id": "dyT2KASL0s5H"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_torch_xyza(lidar_depth, azimuth, zenith):\n",
        "    \"\"\"\n",
        "    Convert LiDAR depth + angular coordinates into an XYZA tensor.\n",
        "\n",
        "    Args:\n",
        "        lidar_depth (torch.Tensor): Radial distances of shape (H, W).\n",
        "        azimuth (torch.Tensor): Azimuth angles in radians, shape (H,).\n",
        "        zenith (torch.Tensor): Zenith angles in radians, shape (W,).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Stacked tensor of shape (4, H, W) containing\n",
        "            X, Y, Z coordinates and a validity mask A.\n",
        "    \"\"\"\n",
        "    # Broadcast azimuth (per row) and zenith (per column) to full image grid\n",
        "    # and convert polar coordinates into Cartesian coordinates.\n",
        "    x = lidar_depth * torch.sin(-azimuth[:, None]) * torch.cos(-zenith[None, :])\n",
        "    y = lidar_depth * torch.cos(-azimuth[:, None]) * torch.cos(-zenith[None, :])\n",
        "    z = lidar_depth * torch.sin(-zenith[None, :])\n",
        "\n",
        "    # A is a binary mask: 1 for valid points, 0 for \"no return\" / far-away\n",
        "    a = torch.where(lidar_depth < 50.0,\n",
        "                    torch.ones_like(lidar_depth),\n",
        "                    torch.zeros_like(lidar_depth))\n",
        "\n",
        "    xyza = torch.stack([x, y, z, a], dim=0)\n",
        "    return xyza"
      ],
      "metadata": {
        "id": "0H2knVe2SQYd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_positions(positions):\n",
        "    \"\"\"\n",
        "    Format a sequence of numerical positions as nicely aligned strings.\n",
        "\n",
        "    Args:\n",
        "        positions (Iterable[float]): Sequence of scalar values.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: List of strings with 4 decimal places.\n",
        "    \"\"\"\n",
        "    return ['{0: .4f}'.format(x) for x in positions]"
      ],
      "metadata": {
        "id": "LeFuy7B7b3Hz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_subset(size, dataset):\n",
        "    \"\"\"\n",
        "    Create a random subset of a given dataset.\n",
        "\n",
        "    Args:\n",
        "        size (int): Desired number of samples in the subset.\n",
        "        dataset (torch.utils.data.Dataset): Dataset to sample from.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.data.Subset: Random subset of the given dataset.\n",
        "    \"\"\"\n",
        "    # Sample unique indices uniformly at random from the dataset\n",
        "    indices = np.random.choice(size, size=size, replace=False)\n",
        "    return Subset(dataset, indices)"
      ],
      "metadata": {
        "id": "g0D8-5Yjy3qt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_loss(epoch, loss, outputs, target, is_train=True, is_debug=False):\n",
        "    \"\"\"\n",
        "    Print a formatted loss line and optionally one example prediction.\n",
        "\n",
        "    Args:\n",
        "        epoch (int): Current epoch index.\n",
        "        loss (float or Tensor): Loss value for this epoch.\n",
        "        outputs (torch.Tensor): Model predictions for the current batch.\n",
        "        target (torch.Tensor): Ground-truth targets for the current batch.\n",
        "        is_train (bool): If True, label as training loss; else validation.\n",
        "        is_debug (bool): If True, also print one prediction/target pair.\n",
        "    \"\"\"\n",
        "\n",
        "    loss_type = \"train loss:\" if is_train else \"valid loss:\"\n",
        "    print(\"epoch\", str(epoch), loss_type, str(loss))\n",
        "\n",
        "    if is_debug:\n",
        "        print(\"example pred:\", format_positions(outputs[0].tolist()))\n",
        "        print(\"example real:\", format_positions(target[0].tolist()))"
      ],
      "metadata": {
        "id": "BOW8rdnSG1Ni"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Final: löschen\n",
        "## move: visualization.py\n",
        "\n",
        "def plot_losses(losses, title=\"Training & Validation Loss Comparison\", figsize=(10,6)):\n",
        "    \"\"\"\n",
        "    Legacy plotting helper to show train/valid losses for multiple models.\n",
        "\n",
        "    Args:\n",
        "        losses (dict): Mapping model_name -> {\"train_losses\": [...],\n",
        "                                              \"valid_losses\": [...]}.\n",
        "        title (str): Plot title.\n",
        "        figsize (tuple): Matplotlib figure size.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for model_name, log in losses.items():\n",
        "        train = log[\"train_losses\"]\n",
        "        valid = log[\"valid_losses\"]\n",
        "\n",
        "        # plot train + valid with different line styles\n",
        "        plt.plot(train, label=f\"{model_name} - train\", linewidth=2)\n",
        "        plt.plot(valid, label=f\"{model_name} - valid\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.xlabel(\"Epochs\", fontsize=14)\n",
        "    plt.ylabel(\"Loss\", fontsize=14)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OWej9tHY4Wjg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and preparation of Data"
      ],
      "metadata": {
        "id": "Zf2LJnXb795e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AssessmentXYZADataset(Dataset):\n",
        "    \"\"\"\n",
        "    Fully preprocessed dataset:\n",
        "\n",
        "    - Loads raw RGB + depth\n",
        "    - Loads azimuth/zenith per class\n",
        "    - Converts depth → XYZA ONCE\n",
        "    - Applies transform_rgb ONCE\n",
        "    - Applies transform_lidar ONCE\n",
        "    - Caches everything in memory\n",
        "\n",
        "    Then __getitem__ is extremely fast.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        root_dir,\n",
        "        start_idx=0,\n",
        "        end_idx=None,\n",
        "        transform_rgb=None,\n",
        "        transform_lidar=None,\n",
        "        shuffle=True,\n",
        "    ):\n",
        "        self.root_dir = Path(root_dir)\n",
        "\n",
        "        # These MUST be deterministic transforms (Resize, ToTensor, Normalize...)\n",
        "        self.transform_rgb = transform_rgb\n",
        "        self.transform_lidar = transform_lidar\n",
        "\n",
        "        self.classes = [\"cubes\", \"spheres\"]\n",
        "        self.label_map = {\"cubes\": 0, \"spheres\": 1}\n",
        "\n",
        "        samples = []\n",
        "        self.az = {}\n",
        "        self.ze = {}\n",
        "\n",
        "        print(f\"Scanning RAW dataset in {root_dir}...\")\n",
        "\n",
        "        # -------- 1. Scan the dataset & load azimuth/zenith --------\n",
        "        for cls in self.classes:\n",
        "            cls_dir   = self.root_dir / cls\n",
        "            rgb_dir   = cls_dir / \"rgb\"\n",
        "            lidar_dir = cls_dir / \"lidar\"\n",
        "\n",
        "            # load az/zen\n",
        "            az_path = cls_dir / \"azimuth.npy\"\n",
        "            ze_path = cls_dir / \"zenith.npy\"\n",
        "            if not az_path.exists() or not ze_path.exists():\n",
        "                raise FileNotFoundError(f\"Missing azimuth/zenith in {cls_dir}\")\n",
        "\n",
        "            self.az[cls] = torch.from_numpy(np.load(az_path)).float()\n",
        "            self.ze[cls] = torch.from_numpy(np.load(ze_path)).float()\n",
        "\n",
        "            # match stems\n",
        "            rgb_files   = sorted(rgb_dir.glob(\"*.png\"))\n",
        "            lidar_files = sorted(lidar_dir.glob(\"*.npy\"))\n",
        "\n",
        "            rgb_stems   = {f.stem for f in rgb_files}\n",
        "            lidar_stems = {f.stem for f in lidar_files}\n",
        "            matching    = sorted(rgb_stems & lidar_stems)\n",
        "\n",
        "            print(f\"{cls}: {len(matching)} paired samples\")\n",
        "\n",
        "            for stem in matching:\n",
        "                samples.append(\n",
        "                    {\n",
        "                        \"class\": cls,\n",
        "                        \"rgb_path\": rgb_dir / f\"{stem}.png\",\n",
        "                        \"depth_path\": lidar_dir / f\"{stem}.npy\",\n",
        "                        \"label\": self.label_map[cls],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "        # -------- Optional shuffle --------\n",
        "        if shuffle:\n",
        "            rng = random.Random(SEED)\n",
        "            rng.shuffle(samples)\n",
        "\n",
        "        if end_idx is None:\n",
        "            end_idx = len(samples)\n",
        "        self.samples = samples[start_idx:end_idx]\n",
        "\n",
        "        # Prepare storage\n",
        "        self.rgb_tensors = []\n",
        "        self.lidar_tensors = []\n",
        "        self.labels = []\n",
        "\n",
        "        # -------- 2. PRECOMPUTE EVERYTHING --------\n",
        "        print(\"Precomputing RGB + XYZA tensors into RAM...\")\n",
        "\n",
        "        for item in tqdm(self.samples, desc=\"Preprocessing\"):\n",
        "            cls = item[\"class\"]\n",
        "            az  = self.az[cls]\n",
        "            ze  = self.ze[cls]\n",
        "\n",
        "            # --- RGB ---\n",
        "            rgb_img = Image.open(item[\"rgb_path\"])\n",
        "            if self.transform_rgb:\n",
        "                rgb_tensor = self.transform_rgb(rgb_img)  # applied once\n",
        "            else:\n",
        "                rgb_tensor = transforms.ToTensor()(rgb_img)\n",
        "\n",
        "            # --- LiDAR XYZA ---\n",
        "            depth_np = np.load(item[\"depth_path\"])\n",
        "            depth_t  = torch.from_numpy(depth_np).float()\n",
        "            xyza = get_torch_xyza(depth_t, az, ze)        # (4,H,W)\n",
        "\n",
        "            if self.transform_lidar:\n",
        "                xyza = self.transform_lidar(xyza)        # applied once\n",
        "\n",
        "            self.rgb_tensors.append(rgb_tensor)\n",
        "            self.lidar_tensors.append(xyza)\n",
        "            self.labels.append(item[\"label\"])\n",
        "\n",
        "        print(f\"Dataset ready: {len(self.samples)} samples preprocessed.\")\n",
        "\n",
        "    # -------- Fast loaders --------\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.rgb_tensors[idx],\n",
        "            self.lidar_tensors[idx],\n",
        "            torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "        )\n"
      ],
      "metadata": {
        "id": "lblVFgnqHP-4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: datasets.py\n",
        "\n",
        "def compute_dataset_mean_std(root_dir):\n",
        "    \"\"\"\n",
        "    Estimate the per-channel mean and std for the RGB+LiDAR data.\n",
        "\n",
        "    Args:\n",
        "        root_dir (str or Path): Root directory passed to AssessmentXYZADataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple[torch.Tensor, torch.Tensor]:\n",
        "            mean and std tensors with shape (C,).\n",
        "    \"\"\"\n",
        "\n",
        "    stats_transforms = transforms.Compose([\n",
        "      transforms.Resize(IMG_SIZE),\n",
        "      transforms.ToImage(),\n",
        "      transforms.ToDtype(torch.float32, scale=True),  # [0,1], 4 channels\n",
        "    ])\n",
        "\n",
        "    stats_dataset = AssessmentXYZADataset(\n",
        "        root_dir=root_dir,\n",
        "        start_idx=0,\n",
        "        end_idx=None,          # or e.g. 1000 to subsample\n",
        "        transform_rgb=stats_transforms,\n",
        "    )\n",
        "\n",
        "    subset_size = min(2000, len(stats_dataset)*0.3)\n",
        "    subset_for_stats = create_subset(size=subset_size)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "    mean = 0.\n",
        "    std = 0.\n",
        "    total = 0\n",
        "\n",
        "    for images, _, _ in tqdm(loader, desc=\"Computing mean/std\"):\n",
        "        images = images.float()       # B, C, H, W\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # compute mean over batch (channels only!)\n",
        "        mean += images.mean(dim=[0, 2, 3]) * batch_size\n",
        "\n",
        "        # compute std over batch\n",
        "        std += images.std(dim=[0, 2, 3]) * batch_size\n",
        "\n",
        "        total += batch_size\n",
        "\n",
        "    mean /= total\n",
        "    std /= total\n",
        "\n",
        "    return mean, std\n"
      ],
      "metadata": {
        "id": "Rd_eqja4y-Y3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dataset_mean_std_neu(root_dir):\n",
        "    \"\"\"\n",
        "    Estimate the per-channel mean and std for the RGB+LiDAR data.\n",
        "\n",
        "    Args:\n",
        "        root_dir (str or Path): Root directory passed to AssessmentXYZADataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple[torch.Tensor, torch.Tensor]:\n",
        "            mean and std tensors with shape (C,).\n",
        "    \"\"\"\n",
        "    stats_transforms = transforms.Compose([\n",
        "        transforms.Resize(IMG_SIZE),\n",
        "        transforms.ToImage(),\n",
        "        transforms.ToDtype(torch.float32, scale=True),  # [0,1], 4 channels\n",
        "    ])\n",
        "\n",
        "    stats_dataset = AssessmentXYZADataset(\n",
        "        root_dir=root_dir,\n",
        "        transform_rgb=stats_transforms,\n",
        "        transform_lidar=None,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(stats_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Accumulate running sum and sum of squares to compute mean/std\n",
        "    channel_sum = torch.zeros(4)\n",
        "    channel_sq_sum = torch.zeros(4)\n",
        "    num_pixels = 0\n",
        "\n",
        "    for rgb, _, _ in tqdm(loader, desc=\"Computing mean/std\"):\n",
        "        # rgb shape: (B, C, H, W)\n",
        "        b, c, h, w = rgb.shape\n",
        "        num_pixels += b * h * w\n",
        "        channel_sum += rgb.sum(dim=[0, 2, 3])\n",
        "        channel_sq_sum += (rgb ** 2).sum(dim=[0, 2, 3])\n",
        "\n",
        "    mean = channel_sum / num_pixels\n",
        "    std = torch.sqrt(channel_sq_sum / num_pixels - mean ** 2)\n",
        "    return mean, std\n"
      ],
      "metadata": {
        "id": "Fx0MbBTy8CrO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Final: dynamisch\n",
        "#root = STORAGE_PATH / \"data\"\n",
        "#mean, std = compute_dataset_mean_std(root_dir=root)"
      ],
      "metadata": {
        "id": "y9jcaSSpS3kd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Final: dynamisch\n",
        "img_transforms = transforms.Compose([\n",
        "    transforms.ToImage(),   # Scales data into [0,1]\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.Normalize(([0.0051, 0.0052, 0.0051, 1.0000]), ([5.8023e-02, 5.8933e-02, 5.8108e-02, 2.4509e-07]))     ## assessment dataset\n",
        "    # transforms.Normalize(mean.tolist(), std.tolist())     ## assessment dataset\n",
        "])"
      ],
      "metadata": {
        "id": "OErXfds6EC8O"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(root_dir, test_frac=0.2):\n",
        "    \"\"\"\n",
        "    Create train / val / test datasets + dataloaders.\n",
        "\n",
        "    - Validation set has exactly VALID_BATCHES * BATCH_SIZE samples.\n",
        "    - Validation DataLoader with drop_last=True → exactly VALID_BATCHES batches.\n",
        "    - Train/test share the remaining samples via a random split.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Base dataset: no internal shuffle, full range\n",
        "    base_dataset = AssessmentXYZADataset(\n",
        "        root_dir,\n",
        "        start_idx=0,\n",
        "        end_idx=None,\n",
        "        transform_rgb=img_transforms,    # adapt if you also pass lidar transforms\n",
        "        transform_lidar=None,\n",
        "        shuffle=False,                   # important: we handle shuffling via indices\n",
        "    )\n",
        "\n",
        "    N = len(base_dataset)\n",
        "    val_size = VALID_BATCHES * BATCH_SIZE\n",
        "\n",
        "    if N <= val_size:\n",
        "        raise ValueError(\n",
        "            f\"Dataset too small: N={N}, but need at least \"\n",
        "            f\"{val_size + 1} samples to have train+test as well.\"\n",
        "        )\n",
        "\n",
        "    # remaining samples after reserving validation\n",
        "    remaining = N - val_size\n",
        "    test_size = int(remaining * test_frac)\n",
        "    train_size = remaining - test_size\n",
        "\n",
        "    print(f\"Total samples: {N}\")\n",
        "    print(f\"Train: {train_size}, Val: {val_size}, Test: {test_size}\")\n",
        "\n",
        "    # 2) One random permutation of all indices (deterministic)\n",
        "    g = torch.Generator().manual_seed(SEED)\n",
        "    perm = torch.randperm(N, generator=g).tolist()\n",
        "\n",
        "    train_idx = perm[:train_size]\n",
        "    val_idx   = perm[train_size:train_size + val_size]\n",
        "    test_idx  = perm[train_size + val_size:]\n",
        "\n",
        "    # 3) Subsets\n",
        "    train_ds = Subset(base_dataset, train_idx)\n",
        "    val_ds   = Subset(base_dataset, val_idx)\n",
        "    test_ds  = Subset(base_dataset, test_idx)\n",
        "\n",
        "    # 4) DataLoaders\n",
        "    train_loader = create_deterministic_training_dataloader(\n",
        "        train_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        drop_last=False,   # for evaluation, we usually don't drop examples\n",
        "    )\n",
        "\n",
        "    return train_ds, train_loader, val_ds, val_loader, test_ds, test_loader"
      ],
      "metadata": {
        "id": "YC_3r7bXSM9U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_dataloader, valid_data, val_dataloader = get_dataloaders(str(STORAGE_PATH / \"multimodal_training_workshop/data/assessment\"))\n",
        "\n",
        "for i, sample in enumerate(train_data):\n",
        "    print(i, *(x.shape for x in sample))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiXY_6-CUYOs",
        "outputId": "27822914-883d-4b6b-8be2-61fe8db726cc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning RAW dataset in /content/drive/MyDrive/Colab Notebooks/Applied Computer Vision/Applied-Computer-Vision-Projects/Multimodal_Learning_02/multimodal_training_workshop/data/assessment...\n",
            "cubes: 2501 paired samples\n",
            "spheres: 9999 paired samples\n",
            "Precomputing RGB + XYZA tensors into RAM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing: 100%|██████████| 12180/12180 [1:30:48<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready: 12180 samples preprocessed.\n",
            "Scanning RAW dataset in /content/drive/MyDrive/Colab Notebooks/Applied Computer Vision/Applied-Computer-Vision-Projects/Multimodal_Learning_02/multimodal_training_workshop/data/assessment...\n",
            "cubes: 2501 paired samples\n",
            "spheres: 9999 paired samples\n",
            "Precomputing RGB + XYZA tensors into RAM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Preprocessing: 100%|██████████| 320/320 [02:22<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready: 320 samples preprocessed.\n",
            "0 torch.Size([4, 64, 64]) torch.Size([4, 64, 64]) torch.Size([])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models\n",
        "\n",
        "Take the EmbedderMaxPool architecture from the workshop and turn it into an encoder that outputs an embedding instead of 9 positions."
      ],
      "metadata": {
        "id": "tF_MGrCQ6MDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedder"
      ],
      "metadata": {
        "id": "uUB25fn4x3Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "class EmbedderMaxPool(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional encoder that down-samples via MaxPool2d and outputs a flat feature vector.\n",
        "\n",
        "    This is used as a shared building block for the early and intermediate\n",
        "    fusion architectures.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, feature_dim=128):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_ch (int): Number of input channels.\n",
        "            feature_dim (int): Number of output channels in the last conv layer.\n",
        "        \"\"\"\n",
        "        kernel_size = 3\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, 32, kernel_size, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, feature_dim, kernel_size, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        # For 64x64 input and 3 pooling steps we end up at 8x8 spatial size.\n",
        "        self.flatten_dim = feature_dim * 8 * 8\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (B, C, H, W).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Flattened feature tensor of shape (B, flatten_dim).\n",
        "        \"\"\"\n",
        "        x = self.pool(F.relu(self.conv1(x)))    # 64x64 -> 32x32\n",
        "        x = self.pool(F.relu(self.conv2(x)))    # 32x32 -> 16x16\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "nL0fCuzT6Pce"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Fusion Model"
      ],
      "metadata": {
        "id": "b1ST72Ch_1ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concept:** Fuse modalities before any deep processing — usually by concatenating channels or inputs.\n",
        "\n",
        "```\n",
        "input = concat(RGB, XYZ)  → shape (8, H, W)\n",
        "-> shared CNN processes everything together\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7Bt4ppI4Zuv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages:**\n",
        "\n",
        "* **Captures Early Cross-Modal Interactions:** Learns joint low-level correlations directly from raw signals.\n",
        "* **Simple & Lightweight**: Easiest fusion method to implement; minimal architectural overhead.\n",
        "* **Effective with Perfect Alignment:** Works well when modalities are tightly synchronized and spatially aligned.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "* **Noise Sensitivity:** One noisy or corrupted modality directly contaminates the shared feature space.\n",
        "* **Strict Alignment Requirement:** Modalities must have matching spatial resolution, alignment, and synchronization.\n",
        "* **Feature Space Mismatch:** Raw modalities differ in scale, units, and distribution; one modality can dominate without careful normalization.\n",
        "* **High Input Dimensionality:** Channel concatenation increases the input size and can require more data and compute to train effectively.\n",
        "* **Limited Flexibility:** Assumes combining low-level signals is beneficial; may underperform when modalities carry different types of information."
      ],
      "metadata": {
        "id": "Q_G-ymxeaDtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "class FullyConnectedHead(nn.Module):\n",
        "    \"\"\"\n",
        "    Fully-connected classification head mapping features to class logits.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim=2):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): Dimensionality of the flattened feature vector.\n",
        "            output_dim (int): Number of output classes.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 100)\n",
        "        self.fc3 = nn.Linear(100, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): Input features of shape (B, input_dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Class logits of shape (B, output_dim).\n",
        "        \"\"\"\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Tr0SNgd11sPy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "class EarlyFusionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Early fusion model that concatenates RGB and LiDAR channels at the input.\n",
        "\n",
        "    The 8-channel tensor (4 RGB-like + 4 XYZA) is passed through a shared\n",
        "    CNN embedder and a fully-connected classification head.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch=8, output_dim=2):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_ch (int): Number of input channels after concatenation.\n",
        "            output_dim (int): Number of output classes.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared embedder for all channels\n",
        "        self.embedder = EmbedderMaxPool(in_ch)\n",
        "\n",
        "        # Fully-connected head on top of the shared embedding\n",
        "        self.fullyConnected = FullyConnectedHead(\n",
        "            input_dim=self.embedder.flatten_dim,\n",
        "            output_dim=output_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (B, in_ch, 64, 64).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Class logits of shape (B, output_dim).\n",
        "        \"\"\"\n",
        "        features = self.embedder(x)     # → (B, 12800)\n",
        "        preds = self.fullyConnected(features)  # → (B, output_dim)\n",
        "        return preds"
      ],
      "metadata": {
        "id": "n0AaZ2PXc7zy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intermediate Fusion Model"
      ],
      "metadata": {
        "id": "7QgOUeNP_44r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concept:** Each modality has its own encoder / feature extractor, and fusion happens after some layers but before classification.\n",
        "\n",
        "```\n",
        "RGB → RGB_conv → RGB_features (C, H, W)\n",
        "LiDAR → LiDAR_conv → LiDAR_features (C, H, W)\n",
        "\n",
        "Fusion → joint_features → FC → output\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Zt0sT9SoasEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages:**\n",
        "\n",
        "* **Specialized Processing:** Each modality gets its own encoder, tailored to its characteristics.\n",
        "* **Learned Representations:** Fusion occurs on higher-level, more discriminative features rather than raw data.\n",
        "* **Flexible Design:** The fusion point can be chosen at different network depths, allowing fine-grained architectural control.\n",
        "* **Easily Extendable:** New modalities can be added by including additional modality-specific branches.\n",
        "\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "* **Architectural Complexity:** Requires designing separate modality-specific encoders and choosing an appropriate fusion point.\n",
        "* **Higher Computational Cost:** More expensive than early fusion due to duplicated feature extractors.\n",
        "* **Fusion Design Sensitivity:** Performance depends on the chosen fusion mechanism (concat, addition, multiplicative, bilinear, attention), which often requires experimentation.\n",
        "* **Depth Selection Challenge:** Deciding how much unimodal processing to perform before fusion can be non-trivial and task-dependent."
      ],
      "metadata": {
        "id": "jiBvpcPQa2pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemented 4 variants:\n",
        "\n",
        "*   Concatenation\n",
        "*   Addition\n",
        "* Hadamard Product (element-wise multiplication)\n",
        "* Matrix-Multiplication\n",
        "\n"
      ],
      "metadata": {
        "id": "899VHVwubGAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Fusion Method | Advantages | Limitations |\n",
        "|---------------|------------|-------------|\n",
        "| **Concatenation** | - Very expressive and flexible<br>- Lets the network learn arbitrary cross-modal interactions<br>- Robust and widely used baseline | - Doubles channel count → more parameters & memory<br>- Computationally heavier<br>- Fusion is unguided; model must discover interactions itself |\n",
        "| **Addition** | - Lightweight (no increase in channels)<br>- Fast and parameter-efficient<br>- Enforces similar feature spaces between modalities | - Assumes features are aligned and comparable<br>- One noisy modality corrupts the other<br>- Sensitive to scale differences between modalities |\n",
        "| **Multiplicative (Hadamard Product)** | - Gating effect: highlights features important in *both* modalities<br>- More expressive than addition, cheaper than concat<br>- Natural for attention-like fusion | - Suppresses features when one modality has low magnitude<br>- Requires careful normalization<br>- Can amplify noise if both activations are high |\n",
        "| **Matrix Multiplication (Bilinear-like)** | - Captures rich pairwise correlations between modalities<br>- Most expressive among all four<br>- Enables true 2nd-order interaction learning | - Very heavy in compute & memory<br>- Requires flattening or dimensionality reduction<br>- Easily overfits; harder to train and tune |\n"
      ],
      "metadata": {
        "id": "EdnoTDCgbe8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "class ConcatIntermediateNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Intermediate fusion model using feature concatenation.\n",
        "\n",
        "    Two separate EmbedderMaxPool encoders are applied to RGB and XYZA\n",
        "    inputs, their flattened features are concatenated, and a shared\n",
        "    FullyConnectedHead maps the joint representation to class logits.\n",
        "    \"\"\"\n",
        "    def __init__(self, rgb_ch, xyz_ch, output_dim, feature_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # Independent Encoders\n",
        "        # RGB learns textures/colors\n",
        "        self.rgb_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "        # LiDAR learns geometry/depth\n",
        "        self.xyz_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "\n",
        "        # Calculate combined dimension\n",
        "        # (200 * 8 * 8) + (200 * 8 * 8)\n",
        "        combined_dim = self.rgb_encoder.flatten_dim + self.xyz_encoder.flatten_dim\n",
        "\n",
        "        # Shared FullyConnected Head\n",
        "        self.head = FullyConnectedHead(input_dim=combined_dim, output_dim=output_dim)\n",
        "\n",
        "    def forward(self, x_rgb, x_xyz):\n",
        "        # Extract features independently\n",
        "        x_rgb = self.rgb_encoder(x_rgb)                                 # (B, D)\n",
        "        x_xyz = self.xyz_encoder(x_xyz)                                 # (B, D)\n",
        "\n",
        "        # Fuse (Concatenate) at the feature level\n",
        "        x_fused = torch.cat((x_rgb, x_xyz), dim=1)                      # (B, 2*D)\n",
        "\n",
        "        # Predict\n",
        "        output = self.head(x_fused)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "OWorX2Vc2mRC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "class AddIntermediateNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Intermediate fusion model using element-wise addition.\n",
        "\n",
        "    Two separate encoders process each modality independently.\n",
        "    The resulting feature vectors must have the same size; they are\n",
        "    added element-wise and passed to a shared FullyConnectedHead.\n",
        "    \"\"\"\n",
        "    def __init__(self, rgb_ch, xyz_ch, output_dim, feature_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # Independent Encoders\n",
        "        # RGB learns textures/colors\n",
        "        self.rgb_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "        # LiDAR learns geometry/depth\n",
        "        self.xyz_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "\n",
        "        # For addition, shapes must match\n",
        "        fused_dim = self.rgb_encoder.flatten_dim                        # same size after addition\n",
        "\n",
        "        # Shared FullyConnected Head\n",
        "        self.head = FullyConnectedHead(input_dim=fused_dim, output_dim=output_dim)\n",
        "\n",
        "    def forward(self, x_rgb, x_xyz):\n",
        "        # Extract features independently\n",
        "        x_rgb = self.rgb_encoder(x_rgb)                                 # (B, D)\n",
        "        x_xyz = self.xyz_encoder(x_xyz)                                 # (B, D)\n",
        "\n",
        "        # Additive fusion in feature space\n",
        "        x_fused = x_rgb + x_xyz                                         # (B, D)\n",
        "\n",
        "        # Predict\n",
        "        output = self.head(x_fused)                                     # (B, output_dim)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "0ho7ej8I6dv8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "class MatmulIntermediateNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Intermediate fusion model using matrix multiplication.\n",
        "\n",
        "    The two modality-specific embeddings are reshaped into matrices\n",
        "    and combined via a bilinear interaction (matrix product) before\n",
        "    the fully-connected head.\n",
        "    \"\"\"\n",
        "    def __init__(self, rgb_ch, xyz_ch, output_dim, feature_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Independent Encoders\n",
        "        # RGB learns textures/colors\n",
        "        self.rgb_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "        # LiDAR learns geometry/depth\n",
        "        self.xyz_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "\n",
        "        # For multiplication, shapes must match\n",
        "        #embedding_dim = self.rgb_encoder.flatten_dim\n",
        "        #fused_dim = embedding_dim * embedding_dim                       # D * D after matmul\n",
        "        self.feature_dim = feature_dim\n",
        "        self.spatial_dim = 8\n",
        "        fused_dim = self.feature_dim * self.spatial_dim * self.spatial_dim\n",
        "\n",
        "\n",
        "        # Shared FullyConnected Head\n",
        "        self.head = FullyConnectedHead(input_dim=fused_dim, output_dim=output_dim)\n",
        "\n",
        "    def forward(self, x_rgb, x_xyz):\n",
        "        B = x_rgb.size(0)\n",
        "\n",
        "        # Extract features independently\n",
        "        x_rgb = self.rgb_encoder(x_rgb)                                 # (B, D)\n",
        "        x_xyz = self.xyz_encoder(x_xyz)                                 # (B, D)\n",
        "\n",
        "        C = self.feature_dim\n",
        "        H = self.spatial_dim\n",
        "        x_rgb = x_rgb.view(B, C, H, H)   # (B, C, 8, 8)\n",
        "        x_xyz = x_xyz.view(B, C, H, H)   # (B, C, 8, 8)\n",
        "\n",
        "        # Per-channel spatial matrix multiplication\n",
        "        x_fused = torch.matmul(x_rgb, x_xyz)                            # (B, C, 8, 8)\n",
        "        x_fused = x_fused.flatten(1)                                # (B, C*8*8)\n",
        "\n",
        "        # Predict\n",
        "        output = self.head(x_fused)                                     # (B, output_dim)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "N2qRIii27b4e"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "class HadamardIntermediateNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Intermediate fusion model using the Hadamard (element-wise) product.\n",
        "\n",
        "    After independent encoding, the feature vectors are multiplied\n",
        "    element-wise to capture multiplicative interactions between\n",
        "    modalities, then fed to the classification head.\n",
        "    \"\"\"\n",
        "    def __init__(self, rgb_ch, xyz_ch, output_dim, feature_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Independent Encoders\n",
        "        # RGB learns textures/colors\n",
        "        self.rgb_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "        # LiDAR learns geometry/depth\n",
        "        self.xyz_encoder = EmbedderMaxPool(in_ch=4, feature_dim=feature_dim)\n",
        "\n",
        "        # For elementwise multiplication, shapes must match\n",
        "        fused_dim = self.rgb_encoder.flatten_dim                        # same size after addition\n",
        "\n",
        "        # Shared FullyConnected Head\n",
        "        self.head = FullyConnectedHead(input_dim=fused_dim, output_dim=output_dim)\n",
        "\n",
        "    def forward(self, x_rgb, x_xyz):\n",
        "        # Extract features independently\n",
        "        x_rgb = self.rgb_encoder(x_rgb)                                 # (B, D)\n",
        "        x_xyz = self.xyz_encoder(x_xyz)                                 # (B, D)\n",
        "\n",
        "        # Multiplicative / gating-like fusion\n",
        "        x_fused = x_rgb * x_xyz                                         # shape: (B, D)\n",
        "\n",
        "        # Predict\n",
        "        output = self.head(x_fused)                                     # (B, output_dim)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "nEz80edk7pfW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Late Fusion Model"
      ],
      "metadata": {
        "id": "r1tl2t3s_8m9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concept:** Each modality is processed completely separately, and only the final predictions or high-level embeddings are fused.\n",
        "\n",
        "```\n",
        "RGB → RGB-Embedder → logits_rgb\n",
        "LiDAR → LiDAR-Embedder → logits_lidar\n",
        "\n",
        "Fusion → final decision\n",
        "```"
      ],
      "metadata": {
        "id": "ACKIMjiocf8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages:**\n",
        "\n",
        "* **Robust to Missing Modalities:** The system can still operate if one modality is noisy, unreliable, or absent.\n",
        "* **Best for Heterogeneous Modalities:** Works well when modalities differ greatly.\n",
        "* **Modular & Simple:** Unimodal models can be trained, debugged, and replaced independently.\n",
        "* **Leverages Existing Models:** Allows the reuse of strong off-the-shelf unimodal experts without architectural changes.\n",
        "\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "* **Missed Interactions:** No joint feature learning — modalities never influence each other during representation learning.\n",
        "* **Limited Expressiveness:** Simple fusion rules (e.g., averaging, weighted sum) cannot capture complex cross-modal relationships.\n",
        "* **Information Loss:** By the time unimodal predictors output logits/embeddings, rich spatial and semantic details may already be discarded, limiting the power of fusion."
      ],
      "metadata": {
        "id": "RSADk-61csKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## move: model.py\n",
        "\n",
        "rgb_net = EmbedderMaxPool(4).to(device)\n",
        "xyz_net = EmbedderMaxPool(4).to(device)\n",
        "\n",
        "## TODO: passiert das woanders nicht?\n",
        "networks = [rgb_net, xyz_net]\n",
        "\n",
        "class LateNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Late fusion model combining unimodal logits.\n",
        "\n",
        "    Two independent classifiers are trained for RGB and LiDAR.\n",
        "    Their logits are then averaged (or combined) at the decision level\n",
        "    to obtain the final prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "        self.rgb = rgb_net\n",
        "        self.xyz = xyz_net\n",
        "\n",
        "        # each embedder outputs flatten_dim (e.g. 12800)\n",
        "        fusion_dim = self.rgb.flatten_dim * 2  # rgb + xyz\n",
        "\n",
        "        # single FullyConnected head in which data is fused\n",
        "        self.fullyConnected = FullyConnectedHead(\n",
        "            input_dim=fusion_dim,\n",
        "            output_dim=output_dim,\n",
        "        )\n",
        "\n",
        "    def forward(self, x_rgb, x_xyz):\n",
        "        # Extract features independently\n",
        "        x_rgb = self.rgb(x_rgb)     # (B, 12800)\n",
        "        x_xyz = self.xyz(x_xyz)     # (B, 12800)\n",
        "\n",
        "        # this concatenates the features from the two branches\n",
        "        x_fused = torch.cat((x_rgb, x_xyz), dim=1)    # (B, 25600)\n",
        "\n",
        "        # Predict\n",
        "        preds = self.fullyConnected(x_fused)           # (B, output_dim)\n",
        "        return preds"
      ],
      "metadata": {
        "id": "YkVKO4UVSwKG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "MJLmVUfdGeXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## move: training.py\n",
        "\n",
        "def train_model(model, optimizer, input_fn, loss_fn, epochs, train_dataloader, val_dataloader, model_save_path, target_idx=-1, log_to_wandb=False, model_name=None):\n",
        "    \"\"\"\n",
        "    Generic training loop for all fusion models.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Model to train.\n",
        "        optimizer (torch.optim.Optimizer): Optimizer instance.\n",
        "        input_fn (callable): Function that maps a batch to model inputs.\n",
        "                             Takes a batch tuple and returns a tuple of tensors.\n",
        "        loss_fn (callable): Loss function (e.g. CrossEntropyLoss).\n",
        "        epochs (int): Number of training epochs.\n",
        "        train_dataloader (DataLoader): Dataloader for training data.\n",
        "        val_dataloader (DataLoader): Dataloader for validation data.\n",
        "        model_save_path (str or Path): Where to save the best model checkpoint.\n",
        "        target_idx (int): If using multi-target labels, index of the target\n",
        "                          to use (-1 for all / default).\n",
        "        log_to_wandb (bool): If True, log metrics to Weights & Biases.\n",
        "        model_name (str or None): Optional label for logging / printing.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing training history:\n",
        "              {\n",
        "                \"train_losses\": [...],\n",
        "                \"valid_losses\": [...],\n",
        "                \"epoch_times\": [...],\n",
        "                \"best_valid_loss\": float,\n",
        "                \"best_model_state_dict\": dict,\n",
        "                \"num_params\": int,\n",
        "                \"max_gpu_mem_mb\": float,\n",
        "              }\n",
        "    \"\"\"\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    epoch_times = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    # Track peak GPU memory usage (if CUDA is available)\n",
        "    max_gpu_mem_mb = 0.0\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "\n",
        "    if use_cuda:\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        start_time = time.time()                  # to track the train time per model\n",
        "        print(f\"Epoch and start time: {epoch} und {start_time}\")\n",
        "\n",
        "        # ----- Training loop -----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            rgb, lidar_xyza, position = batch\n",
        "            rgb = rgb.to(device)\n",
        "            lidar_xyza = lidar_xyza.to(device)\n",
        "            position = position.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            target = batch[target_idx].to(device)\n",
        "            outputs = model(*input_fn(batch))\n",
        "\n",
        "            loss = loss_fn(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss = train_loss / (step + 1)\n",
        "        train_losses.append(train_loss)\n",
        "        print_loss(epoch, train_loss, outputs, target, is_train=True)\n",
        "\n",
        "        # ----- Validation loop -----\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        with torch.no_grad():\n",
        "          for step, batch in enumerate(val_dataloader):\n",
        "              target = batch[target_idx].to(device)\n",
        "              outputs = model(*input_fn(batch))\n",
        "              valid_loss += loss_fn(outputs, target).item()\n",
        "        valid_loss = valid_loss / (step + 1)\n",
        "        valid_losses.append(valid_loss)\n",
        "        print_loss(epoch, valid_loss, outputs, target, is_train=False)\n",
        "\n",
        "        # Save best model based on validation loss\n",
        "        if valid_loss < best_val_loss:\n",
        "          best_val_loss = valid_loss\n",
        "          best_model = model\n",
        "          torch.save(best_model.state_dict(), model_save_path)\n",
        "          print('Found and saved better weights for the model')\n",
        "\n",
        "        # calculate epoch times\n",
        "        epoch_time = time.time() - start_time\n",
        "        epoch_times.append(epoch_time)\n",
        "        epoch_time_formatted = format_time(epoch_time)\n",
        "\n",
        "        # GPU memory usage\n",
        "        if use_cuda:\n",
        "            gpu_mem_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "            max_gpu_mem_mb = max(max_gpu_mem_mb, gpu_mem_mb)\n",
        "\n",
        "        # wandb logging\n",
        "        if log_to_wandb:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"model\": model.__class__.__name__,\n",
        "                    \"epoch\": epoch + 1,\n",
        "                    \"train_loss\": train_loss,\n",
        "                    \"valid_loss\": valid_loss,\n",
        "                    \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "                    \"epoch_time\": epoch_time_formatted,\n",
        "                    \"max_gpu_mem_mb_epoch\": gpu_mem_mb if use_cuda else 0.0,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return train_losses, valid_losses, epoch_times, max_gpu_mem_mb"
      ],
      "metadata": {
        "id": "UmHRslBJGsCp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: training.py\n",
        "\n",
        "def get_early_inputs(batch):\n",
        "    \"\"\"\n",
        "    Prepare inputs for the early fusion model.\n",
        "\n",
        "    Concatenates RGB and XYZA along the channel dimension to obtain\n",
        "    an 8-channel tensor.\n",
        "\n",
        "    Args:\n",
        "        batch (tuple): (rgb, xyz, label) from the dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple[torch.Tensor]: Single-element tuple (inputs_mm_early,).\n",
        "    \"\"\"\n",
        "    inputs_rgb = batch[0].to(device)\n",
        "    inputs_xyz = batch[1].to(device)\n",
        "\n",
        "    # Concatenate along channel dimension: (B, 4, H, W) + (B, 4, H, W) -> (B, 8, H, W)\n",
        "    inputs_mm_early = torch.cat((inputs_rgb, inputs_xyz), 1)\n",
        "    return (inputs_mm_early,)"
      ],
      "metadata": {
        "id": "XEav2OQVSpc-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: training.py\n",
        "\n",
        "def get_inputs(batch):\n",
        "    \"\"\"\n",
        "    Prepare inputs for intermediate/late fusion models.\n",
        "\n",
        "    Returns RGB and XYZA tensors separately so that each modality\n",
        "    can be passed to its own encoder.\n",
        "\n",
        "    Args:\n",
        "        batch (tuple): (rgb, xyz, label) from the dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple[torch.Tensor, torch.Tensor]: (inputs_rgb, inputs_xyz)\n",
        "    \"\"\"\n",
        "    inputs_rgb = batch[0].to(device)\n",
        "    inputs_xyz = batch[1].to(device)\n",
        "    return (inputs_rgb, inputs_xyz)"
      ],
      "metadata": {
        "id": "npcH0IrmSy76"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## move: training.py\n",
        "\n",
        "def compute_class_weights(dataset, num_classes=2):\n",
        "    \"\"\"\n",
        "    Compute inverse-frequency class weights from a dataset.\n",
        "    \"\"\"\n",
        "    # Grab all labels from the prebuilt samples list (cheap)\n",
        "    labels = [sample[\"label\"] for sample in dataset.samples]\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    # Count occurrences of each class\n",
        "    class_counts = torch.bincount(labels, minlength=num_classes).float()\n",
        "\n",
        "    # Inverse-frequency style weights (rarer class -> larger weight)\n",
        "    class_weights = class_counts.sum() / (class_counts + 1e-6)\n",
        "\n",
        "    # Normalize so mean(weight) = 1 (optional but nice)\n",
        "    class_weights = class_weights / class_weights.mean()\n",
        "\n",
        "    return class_weights\n"
      ],
      "metadata": {
        "id": "Glijei9Pbh8y"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## stay\n",
        "FEATURE_DIM = 128\n",
        "\n",
        "set_seeds(SEED)\n",
        "\n",
        "class_weights = compute_class_weights(train_data, NUM_CLASSES).to(device)\n",
        "loss_func = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "metrics = {}   # store losses for each model\n",
        "\n",
        "# Defines fusion models to train and compare\n",
        "models_to_train = {\n",
        "    \"early_fusion\": EarlyFusionModel(in_ch=8, output_dim=NUM_CLASSES).to(device),\n",
        "    \"intermediate_fusion_concat\": ConcatIntermediateNet(4, 4, output_dim=NUM_CLASSES, feature_dim=FEATURE_DIM).to(device),\n",
        "    \"intermediate_fusion_matmul\": MatmulIntermediateNet(4, 4, output_dim=NUM_CLASSES, feature_dim=FEATURE_DIM).to(device),\n",
        "    \"intermediate_fusion_hadamard\": HadamardIntermediateNet(4, 4, output_dim=NUM_CLASSES, feature_dim=FEATURE_DIM).to(device),\n",
        "    \"intermediate_fusion_add\": AddIntermediateNet(4, 4, output_dim=NUM_CLASSES, feature_dim=FEATURE_DIM).to(device),\n",
        "    \"late_fusion\": LateNet(output_dim=NUM_CLASSES).to(device),\n",
        "}\n",
        "\n",
        "# Directory where best model is saved\n",
        "checkpoint_dir = STORAGE_PATH / \"checkpoints\"\n",
        "checkpoint_dir.mkdir(exist_ok=True)\n",
        "\n",
        "\n",
        "# === Main experiment loop over all fusion strategies ===\n",
        "for name, model in models_to_train.items():\n",
        "  model_save_path = checkpoint_dir / f\"{name}.pth\"\n",
        "\n",
        "  # Number of trainable parameters (for the comparison table)\n",
        "  num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "  opt = Adam(model.parameters(), lr=LR)\n",
        "\n",
        "  # Initialize a new Weights & Biases run for this model.\n",
        "  init_wandb(\n",
        "      model=model,\n",
        "      fusion_name=name,\n",
        "      num_params=num_params,\n",
        "      opt_name = opt.__class__.__name__)\n",
        "\n",
        "  # Choose the proper input function depending on the fusion strategy:\n",
        "  if name == \"early_fusion\":\n",
        "    input_fn = get_early_inputs\n",
        "  else:\n",
        "    input_fn = get_inputs\n",
        "\n",
        "  train_losses, valid_losses, epoch_times, max_gpu_mem_mb = train_model(\n",
        "    model=model,\n",
        "    optimizer=opt,\n",
        "    input_fn=input_fn,\n",
        "    epochs=EPOCHS,\n",
        "    loss_fn=loss_func,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    model_save_path=model_save_path,\n",
        "    target_idx=-1,   # last element in batch is target\n",
        "    log_to_wandb=True,\n",
        "    model_name=name\n",
        "  )\n",
        "\n",
        "  metrics[name] = {\n",
        "      \"train_losses\": train_losses,\n",
        "      \"valid_losses\": valid_losses,\n",
        "      \"epoch_times\": epoch_times,\n",
        "      \"best_valid_loss\": min(valid_losses),\n",
        "      \"max_gpu_mem_mb\": max_gpu_mem_mb,\n",
        "      \"num_params\": num_params,\n",
        "  }\n",
        "\n",
        "  # End wandb run before starting the next model\n",
        "  wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_tt2AIIOA6Jj",
        "outputId": "c7c839f5-9546-4198-e8d6-ad195e0dec49"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All random seeds set to 51 for reproducibility\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_071033-tc9mwz57</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/tc9mwz57' target=\"_blank\">early_fusion_run</a></strong> to <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/tc9mwz57' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/tc9mwz57</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch and start time: 0 und 1765005036.0889552\n",
            "epoch 0 train loss: 0.5626552411600163\n",
            "epoch 0 valid loss: 0.4684498369693756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:08<01:52,  8.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 1 und 1765005044.1252787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:12<01:17,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 train loss: 0.22926945835842114\n",
            "epoch 1 valid loss: 0.07396550886332989\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 2 und 1765005048.5788617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:17<01:04,  5.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 train loss: 0.05067737131734918\n",
            "epoch 2 valid loss: 0.02009746680269018\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 3 und 1765005053.3563566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:21<00:55,  5.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 train loss: 0.06604842481174274\n",
            "epoch 3 valid loss: 0.03209065881092101\n",
            "Epoch and start time: 4 und 1765005057.849871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:26<00:48,  4.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 train loss: 0.01383644383167848\n",
            "epoch 4 valid loss: 0.0037152578137465754\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 5 und 1765005062.4538553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:31<00:43,  4.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 train loss: 0.0018238768916872734\n",
            "epoch 5 valid loss: 0.000846026414365042\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 6 und 1765005067.2065217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [00:35<00:37,  4.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 train loss: 0.0007154490645342249\n",
            "epoch 6 valid loss: 0.0006075426346797031\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 7 und 1765005071.7509282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [00:40<00:32,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 train loss: 0.0003666144444985931\n",
            "epoch 7 valid loss: 0.0005699772520529223\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 8 und 1765005076.1746297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [00:44<00:28,  4.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 train loss: 0.00023014690466784248\n",
            "epoch 8 valid loss: 0.000332994472955761\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 9 und 1765005081.0345235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [00:49<00:23,  4.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 train loss: 0.00016323271503743424\n",
            "epoch 9 valid loss: 0.0002044604137154238\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 10 und 1765005085.5750177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [00:53<00:18,  4.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 train loss: 0.00010922218810169158\n",
            "epoch 10 valid loss: 0.00018235650459246243\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 11 und 1765005089.992157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [00:58<00:13,  4.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 train loss: 8.541159608715757e-05\n",
            "epoch 11 valid loss: 0.00012150136435593595\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 12 und 1765005094.825548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:03<00:09,  4.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 train loss: 5.97618234911878e-05\n",
            "epoch 12 valid loss: 9.697055847937008e-05\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 13 und 1765005099.3486795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [01:07<00:04,  4.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 train loss: 4.673152169755811e-05\n",
            "epoch 13 valid loss: 5.133316840328916e-05\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 14 und 1765005103.7766128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:12<00:00,  4.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 train loss: 3.6236139088654646e-05\n",
            "epoch 14 valid loss: 6.648294697697565e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>epoch_time</td><td>00m 04s</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>497.78516</td></tr><tr><td>model</td><td>EarlyFusionModel</td></tr><tr><td>train_loss</td><td>4e-05</td></tr><tr><td>valid_loss</td><td>7e-05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">early_fusion_run</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/tc9mwz57' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/tc9mwz57</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_071033-tc9mwz57/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_071149-ry503x9l</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ry503x9l' target=\"_blank\">intermediate_fusion_concat_run</a></strong> to <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ry503x9l' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ry503x9l</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch and start time: 0 und 1765005110.306817\n",
            "epoch 0 train loss: 0.4158123059296294\n",
            "epoch 0 valid loss: 0.1366640694439411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:11<02:44, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 1 und 1765005122.0550432\n",
            "epoch 1 train loss: 0.0715658043866585\n",
            "epoch 1 valid loss: 0.03430790789425373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:19<02:03,  9.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 2 und 1765005130.0270822\n",
            "epoch 2 train loss: 0.012071977519984725\n",
            "epoch 2 valid loss: 0.012303305171371903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:28<01:52,  9.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 3 und 1765005139.21017\n",
            "epoch 3 train loss: 0.0030194051546411508\n",
            "epoch 3 valid loss: 0.00046799747215118257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:36<01:37,  8.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 4 und 1765005147.270188\n",
            "epoch 4 train loss: 0.00046740791432105315\n",
            "epoch 4 valid loss: 0.0002635198703501374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:46<01:29,  8.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 5 und 1765005156.4820273\n",
            "epoch 5 train loss: 0.00023755638956716115\n",
            "epoch 5 valid loss: 0.0001521132079687959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:54<01:18,  8.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 6 und 1765005164.5833051\n",
            "epoch 6 train loss: 0.00014300718042692861\n",
            "epoch 6 valid loss: 9.066001548490022e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [01:04<01:12,  9.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 7 und 1765005174.390381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [01:11<01:00,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 train loss: 9.20517837926127e-05\n",
            "epoch 7 valid loss: 9.952585719474882e-05\n",
            "Epoch and start time: 8 und 1765005182.2972796\n",
            "epoch 8 train loss: 6.379534812385588e-05\n",
            "epoch 8 valid loss: 5.019477125642879e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:20<00:52,  8.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 9 und 1765005191.1106935\n",
            "epoch 9 train loss: 4.839576538684971e-05\n",
            "epoch 9 valid loss: 3.929074396182841e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:28<00:42,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 10 und 1765005199.050444\n",
            "epoch 10 train loss: 3.01175808645164e-05\n",
            "epoch 10 valid loss: 2.5510177158594162e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:37<00:34,  8.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 11 und 1765005207.6410444\n",
            "epoch 11 train loss: 2.305481535035812e-05\n",
            "epoch 11 valid loss: 2.477988711575563e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:45<00:25,  8.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 12 und 1765005215.703691\n",
            "epoch 12 train loss: 1.4966880498241452e-05\n",
            "epoch 12 valid loss: 2.162147612239096e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:53<00:16,  8.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 13 und 1765005224.2352352\n",
            "epoch 13 train loss: 1.04218002561452e-05\n",
            "epoch 13 valid loss: 1.1236359239319426e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [02:02<00:08,  8.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 14 und 1765005232.3303764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:09<00:00,  8.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 train loss: 7.63765827800823e-06\n",
            "epoch 14 valid loss: 1.335593517524103e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>epoch_time</td><td>00m 07s</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>672.74072</td></tr><tr><td>model</td><td>ConcatIntermediateNe...</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>valid_loss</td><td>1e-05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">intermediate_fusion_concat_run</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ry503x9l' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ry503x9l</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_071149-ry503x9l/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_071400-wdcglu3b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/wdcglu3b' target=\"_blank\">intermediate_fusion_matmul_run</a></strong> to <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/wdcglu3b' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/wdcglu3b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch and start time: 0 und 1765005242.334501\n",
            "epoch 0 train loss: 0.3378340874798596\n",
            "epoch 0 valid loss: 0.08502432256937027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:08<02:04,  8.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 1 und 1765005251.195422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:15<01:40,  7.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 train loss: 0.054603924640105106\n",
            "epoch 1 valid loss: 0.021005621115909888\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 2 und 1765005258.1429372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:22<01:27,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 train loss: 0.012223470199705844\n",
            "epoch 2 valid loss: 0.010335848412796621\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 3 und 1765005264.876252\n",
            "epoch 3 train loss: 0.01688329232934776\n",
            "epoch 3 valid loss: 0.006406925574992783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:30<01:22,  7.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 4 und 1765005272.6614625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:36<01:11,  7.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 train loss: 0.0069763711703360876\n",
            "epoch 4 valid loss: 0.028408014619344613\n",
            "Epoch and start time: 5 und 1765005279.247396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:44<01:05,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 train loss: 0.02260191390746603\n",
            "epoch 5 valid loss: 0.007511687416990753\n",
            "Epoch and start time: 6 und 1765005286.7542028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [00:51<00:56,  7.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 train loss: 0.0059698940881817535\n",
            "epoch 6 valid loss: 0.02070057046439615\n",
            "Epoch and start time: 7 und 1765005293.38205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [00:57<00:49,  7.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 train loss: 0.0031496025087350468\n",
            "epoch 7 valid loss: 0.003291310154236271\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 8 und 1765005300.2981951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:04<00:41,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 train loss: 0.0024542619601833704\n",
            "epoch 8 valid loss: 0.003007370540899501\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 9 und 1765005306.9793313\n",
            "epoch 9 train loss: 0.00019992961692298799\n",
            "epoch 9 valid loss: 0.0007426005536444791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:11<00:34,  6.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 10 und 1765005313.9706545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:18<00:27,  6.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 train loss: 0.0169540402900905\n",
            "epoch 10 valid loss: 0.0008342342487139831\n",
            "Epoch and start time: 11 und 1765005320.580727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:25<00:20,  6.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 train loss: 0.00038083992718776174\n",
            "epoch 11 valid loss: 6.749028859758255e-05\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 12 und 1765005327.628587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:31<00:13,  6.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 train loss: 0.00980529329088275\n",
            "epoch 12 valid loss: 0.07450709528638981\n",
            "Epoch and start time: 13 und 1765005334.224564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [01:39<00:06,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 train loss: 0.005790905225140962\n",
            "epoch 13 valid loss: 0.0017946076811085731\n",
            "Epoch and start time: 14 und 1765005341.6645494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:45<00:00,  7.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 train loss: 8.797138192589221e-05\n",
            "epoch 14 valid loss: 0.0006844121951559146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▃▂▂▃▂▃▁▁▁▁▁▇▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>epoch_time</td><td>00m 06s</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>643.09326</td></tr><tr><td>model</td><td>MatmulIntermediateNe...</td></tr><tr><td>train_loss</td><td>9e-05</td></tr><tr><td>valid_loss</td><td>0.00068</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">intermediate_fusion_matmul_run</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/wdcglu3b' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/wdcglu3b</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_071400-wdcglu3b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_071548-ws3db2cb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ws3db2cb' target=\"_blank\">intermediate_fusion_hadamard_run</a></strong> to <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ws3db2cb' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ws3db2cb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch and start time: 0 und 1765005350.0117037\n",
            "epoch 0 train loss: 0.43443873283502304\n",
            "epoch 0 valid loss: 0.09456979278475046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:08<02:03,  8.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 1 und 1765005358.8608503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:15<01:38,  7.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 train loss: 0.06574084258417746\n",
            "epoch 1 valid loss: 0.03264795758295804\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 2 und 1765005365.5443428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:22<01:25,  7.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 train loss: 0.026173323980305883\n",
            "epoch 2 valid loss: 0.04030508247960825\n",
            "Epoch and start time: 3 und 1765005372.1862035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:28<01:16,  6.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 train loss: 0.017238091859670884\n",
            "epoch 3 valid loss: 0.003409771394217387\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 4 und 1765005378.8978817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:35<01:08,  6.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 train loss: 0.00601055969761642\n",
            "epoch 4 valid loss: 0.004989977351942798\n",
            "Epoch and start time: 5 und 1765005385.6157677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:42<01:01,  6.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 train loss: 0.0020461679568355567\n",
            "epoch 5 valid loss: 0.001644591582044086\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 6 und 1765005392.3212042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [00:49<00:54,  6.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 train loss: 0.02509512400224235\n",
            "epoch 6 valid loss: 0.06618755301460624\n",
            "Epoch and start time: 7 und 1765005399.0235138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [00:55<00:47,  6.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 train loss: 0.0037954021857666176\n",
            "epoch 7 valid loss: 0.0012642018087717587\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 8 und 1765005405.7100494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:02<00:40,  6.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 train loss: 0.000742217525391341\n",
            "epoch 8 valid loss: 0.0009175047627650202\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 9 und 1765005412.5280306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:09<00:33,  6.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 train loss: 0.0005232832813642349\n",
            "epoch 9 valid loss: 0.0005017029782266036\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 10 und 1765005419.0891159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:15<00:26,  6.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 train loss: 9.14748086947102e-05\n",
            "epoch 10 valid loss: 0.00028336346595096983\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 11 und 1765005425.848545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:22<00:20,  6.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 train loss: 4.127770776077785e-05\n",
            "epoch 11 valid loss: 0.0002461238212333683\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 12 und 1765005432.4948022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:29<00:13,  6.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 train loss: 3.059463001840369e-05\n",
            "epoch 12 valid loss: 0.0002645133844424663\n",
            "Epoch and start time: 13 und 1765005439.955488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [01:36<00:06,  6.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 train loss: 2.039952046346783e-05\n",
            "epoch 13 valid loss: 0.00010825360006379014\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 14 und 1765005446.5095859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:43<00:00,  6.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 train loss: 1.484446761808735e-05\n",
            "epoch 14 valid loss: 0.00016738145174599595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▃▄▁▁▁▆▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>epoch_time</td><td>00m 06s</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>675.4458</td></tr><tr><td>model</td><td>HadamardIntermediate...</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>valid_loss</td><td>0.00017</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">intermediate_fusion_hadamard_run</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ws3db2cb' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/ws3db2cb</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_071548-ws3db2cb/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_071733-k99r55ep</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/k99r55ep' target=\"_blank\">intermediate_fusion_add_run</a></strong> to <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/k99r55ep' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/k99r55ep</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch and start time: 0 und 1765005454.8416016\n",
            "epoch 0 train loss: 0.5132971908505025\n",
            "epoch 0 valid loss: 0.30965492874383926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:08<02:05,  8.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 1 und 1765005463.820988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:15<01:38,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 train loss: 0.17470852745157717\n",
            "epoch 1 valid loss: 0.052129405178129674\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 2 und 1765005470.4466987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:22<01:26,  7.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 train loss: 0.03897266684492168\n",
            "epoch 2 valid loss: 0.015614924940746278\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 3 und 1765005477.2490182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:28<01:16,  6.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 train loss: 0.014068127959456576\n",
            "epoch 3 valid loss: 0.012367333471775054\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 4 und 1765005483.8263211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:35<01:08,  6.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 train loss: 0.01873248172502683\n",
            "epoch 4 valid loss: 0.014096205856185406\n",
            "Epoch and start time: 5 und 1765005490.5117226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:42<01:01,  6.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 train loss: 0.007281941768728996\n",
            "epoch 5 valid loss: 0.001488131721271202\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 6 und 1765005497.2326295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [00:49<00:54,  6.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 train loss: 0.0021783548255945406\n",
            "epoch 6 valid loss: 0.0004578752415909548\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 7 und 1765005503.986831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [00:55<00:47,  6.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 train loss: 0.000372410735022449\n",
            "epoch 7 valid loss: 0.0002347895110688114\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 8 und 1765005510.6161344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:02<00:40,  6.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 train loss: 0.0003137186160206272\n",
            "epoch 8 valid loss: 0.0003707920084480065\n",
            "Epoch and start time: 9 und 1765005517.2175806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:09<00:33,  6.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 train loss: 0.0001651190067982019\n",
            "epoch 9 valid loss: 0.0002857755314039423\n",
            "Epoch and start time: 10 und 1765005524.0897448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:15<00:26,  6.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 train loss: 0.00010507083675622054\n",
            "epoch 10 valid loss: 0.00013008816797537292\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 11 und 1765005530.7725332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:22<00:20,  6.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 train loss: 6.59830481099352e-05\n",
            "epoch 11 valid loss: 8.209501336295944e-05\n",
            "Found and saved better weights for the model\n",
            "Epoch and start time: 12 und 1765005537.44156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:29<00:13,  6.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 train loss: 5.3507167214885806e-05\n",
            "epoch 12 valid loss: 9.117456517060418e-05\n",
            "Epoch and start time: 13 und 1765005544.0081196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [01:35<00:06,  6.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 train loss: 3.2183919515691325e-05\n",
            "epoch 13 valid loss: 0.00014134061800064046\n",
            "Epoch and start time: 14 und 1765005550.6452441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:42<00:00,  6.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 train loss: 2.385502846415103e-05\n",
            "epoch 14 valid loss: 6.031195515561194e-05\n",
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>epoch_time</td><td>00m 06s</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>707.79834</td></tr><tr><td>model</td><td>AddIntermediateNet</td></tr><tr><td>train_loss</td><td>2e-05</td></tr><tr><td>valid_loss</td><td>6e-05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">intermediate_fusion_add_run</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/k99r55ep' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/k99r55ep</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_071733-k99r55ep/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_071917-rzwbboua</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/rzwbboua' target=\"_blank\">late_fusion_run</a></strong> to <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/rzwbboua' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/rzwbboua</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch and start time: 0 und 1765005559.2316113\n",
            "epoch 0 train loss: 0.4135735065480204\n",
            "epoch 0 valid loss: 0.16078734695911406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:11<02:40, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 1 und 1765005570.7335384\n",
            "epoch 1 train loss: 0.1168279757858009\n",
            "epoch 1 valid loss: 0.03428221521899104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:19<02:03,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 2 und 1765005578.7933438\n",
            "epoch 2 train loss: 0.03690824886986153\n",
            "epoch 2 valid loss: 0.008259015413932503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:28<01:50,  9.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 3 und 1765005587.60984\n",
            "epoch 3 train loss: 0.007790649759063901\n",
            "epoch 3 valid loss: 0.0021182636526646094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:36<01:35,  8.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 4 und 1765005595.5567136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:44<01:24,  8.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 train loss: 0.007788954795557258\n",
            "epoch 4 valid loss: 0.0027640352534945125\n",
            "Epoch and start time: 5 und 1765005603.4966822\n",
            "epoch 5 train loss: 0.00130579280581323\n",
            "epoch 5 valid loss: 0.0004897572771369596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:52<01:15,  8.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 6 und 1765005611.792534\n",
            "epoch 6 train loss: 0.0003617342461869779\n",
            "epoch 6 valid loss: 0.00038091625574452335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [01:00<01:06,  8.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 7 und 1765005619.8321285\n",
            "epoch 7 train loss: 0.00014998853726554348\n",
            "epoch 7 valid loss: 0.0003036843791960564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [01:08<00:57,  8.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 8 und 1765005627.9135695\n",
            "epoch 8 train loss: 8.708953094020743e-05\n",
            "epoch 8 valid loss: 0.00016106459670481855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:16<00:48,  8.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 9 und 1765005635.938494\n",
            "epoch 9 train loss: 5.281010533592148e-05\n",
            "epoch 9 valid loss: 0.00015495268596623645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:24<00:40,  8.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 10 und 1765005644.0027256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:32<00:32,  8.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 train loss: 3.740535941275132e-05\n",
            "epoch 10 valid loss: 0.00016043959449234534\n",
            "Epoch and start time: 11 und 1765005652.0454452\n",
            "epoch 11 train loss: 2.6835513454228163e-05\n",
            "epoch 11 valid loss: 7.769166777507052e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:41<00:24,  8.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 12 und 1765005660.5765595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:49<00:16,  8.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 train loss: 1.678644077115546e-05\n",
            "epoch 12 valid loss: 8.505542148782297e-05\n",
            "Epoch and start time: 13 und 1765005668.4738462\n",
            "epoch 13 train loss: 1.0846715312707925e-05\n",
            "epoch 13 valid loss: 6.258662603215725e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [01:57<00:08,  8.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n",
            "Epoch and start time: 14 und 1765005676.526465\n",
            "epoch 14 train loss: 7.629756251428956e-06\n",
            "epoch 14 valid loss: 4.534089036951627e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:05<00:00,  8.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found and saved better weights for the model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>epoch_time</td><td>00m 08s</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>max_gpu_mem_mb_epoch</td><td>833.40088</td></tr><tr><td>model</td><td>LateNet</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>valid_loss</td><td>5e-05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">late_fusion_run</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/rzwbboua' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/rzwbboua</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_071917-rzwbboua/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "xux2ArSO_Nnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## move: visualization.py\n",
        "\n",
        "def plot_losses(loss_dict, title=\"Validation Loss per Model\", ylabel=\"Loss\", xlabel=\"Epoch\"):\n",
        "    \"\"\"\n",
        "    Plot validation loss curves for multiple models.\n",
        "\n",
        "    Args:\n",
        "        loss_dict (dict): Mapping \"model_name\" -> list_of_losses (same length).\n",
        "        title (str): Plot title.\n",
        "        ylabel (str): Label for y-axis.\n",
        "        xlabel (str): Label for x-axis.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8,5))\n",
        "\n",
        "    # Auto-generate x-axis based on first model\n",
        "    any_key = next(iter(loss_dict))\n",
        "    epochs = range(len(loss_dict[any_key]))\n",
        "\n",
        "    for model_name, losses in loss_dict.items():\n",
        "        plt.plot(epochs, losses, label=model_name)\n",
        "\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "l9P8dcwrDP7y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute avg_epoch_time\n",
        "avg_epoch_time = sum(epoch_times) / len(epoch_times)"
      ],
      "metadata": {
        "id": "5O6OQ7SEbSN9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_fusion_comparison_df(metrics, name_map=None):\n",
        "    rows = []\n",
        "    for key, m in metrics.items():\n",
        "        avg_train_loss = float(np.mean(m[\"train_losses\"]))\n",
        "        avg_valid_loss = float(np.mean(m[\"valid_losses\"]))\n",
        "        avg_epoch_time = float(np.mean(m[\"epoch_times\"]))\n",
        "        rows.append({\n",
        "            \"Fusion Strategy\": name_map.get(key, key) if name_map else key,\n",
        "            \"Avg Valid Loss\": avg_valid_loss,\n",
        "            \"Best Valid Loss\": float(m[\"best_valid_loss\"]),\n",
        "            \"Num of params\": int(m[\"num_params\"]),\n",
        "            \"Avg time per epoch (min:s)\": avg_epoch_time,\n",
        "            \"GPU Memory (MB, max)\": float(m[\"max_gpu_mem_mb\"]),\n",
        "        })\n",
        "    return pd.DataFrame(rows)"
      ],
      "metadata": {
        "id": "eQkndCwi72Df"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_map = {\n",
        "    \"early_fusion\": \"Early Fusion\",\n",
        "    \"late_fusion\": \"Late Fusion\",\n",
        "    \"intermediate_fusion_concat\": \"Intermediate (Concat)\",\n",
        "    \"intermediate_fusion_matmul\": \"Intermediate (Multiplicative)\",\n",
        "    \"intermediate_fusion_hadamard\": \"Intermediate (Hadamard)\",\n",
        "    \"intermediate_fusion_add\": \"Intermediate (Add)\",\n",
        "}"
      ],
      "metadata": {
        "id": "LxzPr1PhkjSi"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_dict = {name: m[\"valid_losses\"] for name, m in metrics.items()}\n",
        "plot_losses(loss_dict, title=\"Validation Loss per Model\")\n",
        "\n",
        "df_comparison = build_fusion_comparison_df(metrics, name_map)\n",
        "df_comparison"
      ],
      "metadata": {
        "id": "RSfWbBea6u4x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "267809fd-fee6-4bed-bd0a-6526ebaf639c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Fusion Strategy  Avg Valid Loss  Best Valid Loss  \\\n",
              "0                   Early Fusion        0.040093         0.000051   \n",
              "1          Intermediate (Concat)        0.012302         0.000011   \n",
              "2  Intermediate (Multiplicative)        0.017621         0.000067   \n",
              "3        Intermediate (Hadamard)        0.016501         0.000108   \n",
              "4             Intermediate (Add)        0.027147         0.000060   \n",
              "5                    Late Fusion        0.014009         0.000045   \n",
              "\n",
              "   Num of params  Avg time per epoch (min:s)  GPU Memory (MB, max)  \n",
              "0        8387990                    4.824955            497.785156  \n",
              "1       16672374                    8.649188            672.740723  \n",
              "2        8480374                    7.058182            643.093262  \n",
              "3        8480374                    6.874232            675.445801  \n",
              "4        8480374                    6.826059            707.798340  \n",
              "5       16672374                    8.357273            833.400879  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a14ae442-3793-4432-94dc-eea9ba02c3b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fusion Strategy</th>\n",
              "      <th>Avg Valid Loss</th>\n",
              "      <th>Best Valid Loss</th>\n",
              "      <th>Num of params</th>\n",
              "      <th>Avg time per epoch (min:s)</th>\n",
              "      <th>GPU Memory (MB, max)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Early Fusion</td>\n",
              "      <td>0.040093</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>8387990</td>\n",
              "      <td>4.824955</td>\n",
              "      <td>497.785156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Intermediate (Concat)</td>\n",
              "      <td>0.012302</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>16672374</td>\n",
              "      <td>8.649188</td>\n",
              "      <td>672.740723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Intermediate (Multiplicative)</td>\n",
              "      <td>0.017621</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>8480374</td>\n",
              "      <td>7.058182</td>\n",
              "      <td>643.093262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Intermediate (Hadamard)</td>\n",
              "      <td>0.016501</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>8480374</td>\n",
              "      <td>6.874232</td>\n",
              "      <td>675.445801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Intermediate (Add)</td>\n",
              "      <td>0.027147</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>8480374</td>\n",
              "      <td>6.826059</td>\n",
              "      <td>707.798340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Late Fusion</td>\n",
              "      <td>0.014009</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>16672374</td>\n",
              "      <td>8.357273</td>\n",
              "      <td>833.400879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a14ae442-3793-4432-94dc-eea9ba02c3b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a14ae442-3793-4432-94dc-eea9ba02c3b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a14ae442-3793-4432-94dc-eea9ba02c3b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f94408b5-c8eb-450e-9270-8a62ec18e7d0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f94408b5-c8eb-450e-9270-8a62ec18e7d0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f94408b5-c8eb-450e-9270-8a62ec18e7d0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_791655a3-2a16-440f-9940-d5944264e60c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_comparison')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_791655a3-2a16-440f-9940-d5944264e60c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_comparison');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_comparison",
              "summary": "{\n  \"name\": \"df_comparison\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Fusion Strategy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Early Fusion\",\n          \"Intermediate (Concat)\",\n          \"Late Fusion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg Valid Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010564619241336946,\n        \"min\": 0.012302339218849738,\n        \"max\": 0.040093224999376016,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.040093224999376016,\n          0.012302339218849738,\n          0.014008824392873482\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best Valid Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.165331259265801e-05,\n        \"min\": 1.1236359239319426e-05,\n        \"max\": 0.00010825360006379014,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5.133316840328916e-05,\n          1.1236359239319426e-05,\n          4.534089036951627e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Num of params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4242408,\n        \"min\": 8387990,\n        \"max\": 16672374,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          8387990,\n          16672374,\n          8480374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Avg time per epoch (min:s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3626662510055827,\n        \"min\": 4.824954811731974,\n        \"max\": 8.649188137054443,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.824954811731974,\n          8.649188137054443,\n          8.357273117701213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GPU Memory (MB, max)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 108.19435860640783,\n        \"min\": 497.78515625,\n        \"max\": 833.40087890625,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          497.78515625,\n          672.74072265625,\n          833.40087890625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logs the comparison table to wandb\n",
        "wandb.init(\n",
        "    project=\"cilp-extended-assessment\",   # your project name\n",
        "    name=\"fusion_comparison_all\",\n",
        "    job_type=\"analysis\",\n",
        ")\n",
        "\n",
        "fusion_comparison_table = wandb.Table(dataframe=df_comparison)\n",
        "wandb.log({\"fusion_comparison\": fusion_comparison_table})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "aL_anEO28AnC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "bceb0a72-2a20-4c71-b878-5f7c17d87f8d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fusion_comparison_all</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/2fhytvef' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/2fhytvef</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_072638-2fhytvef/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_073140-xmbej7ez</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/xmbej7ez' target=\"_blank\">fusion_comparison_all</a></strong> to <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/xmbej7ez' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/xmbej7ez</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fusion_comparison_all</strong> at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/xmbej7ez' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment/runs/xmbej7ez</a><br> View project at: <a href='https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/michele-marschner-university-of-potsdam/cilp-extended-assessment</a><br>Synced 4 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251206_073140-xmbej7ez/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report (200-400 words)\n",
        "*   Which architecture performed best and why\n",
        "*   Trade-offs between parameter count and performance\n",
        "* Recommendations for when to use each approach\n"
      ],
      "metadata": {
        "id": "99QIuV7eXflz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trade-offs between parameter count and performance\n",
        "\n",
        "* Übersicht in metrics table\n",
        "* Performance ist Geschwindigkeit oder finaler Outcome gemeint?"
      ],
      "metadata": {
        "id": "9iIP6aBxXnEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When to use**\n",
        "\n",
        "**Early Fusion:**\n",
        "* Aligned, closely related low-level modalities and comparable features\n",
        "* Simple setup; avoid if sensors are noisy\n",
        "\n",
        "**Intermediate Fusion:**\n",
        "* Modalities with different structure that benefit from separate early processing in order to learn modality-specific features   \n",
        "* best overall balance of performance and flexibility\n",
        "\n",
        "**Late Fusion:**\n",
        "* Strong, independent unimodal predictors, to combine their strengths\n",
        "* ideal for heterogeneous or missing modalities\n",
        "* robust fallback when one modality fails"
      ],
      "metadata": {
        "id": "Ad-R30zkczAj"
      }
    }
  ]
}